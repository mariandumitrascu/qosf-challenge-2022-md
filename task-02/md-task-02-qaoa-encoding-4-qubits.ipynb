{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ccfe335-e640-4b2c-b933-cba2bd38fab7",
   "metadata": {},
   "source": [
    "# Task 2 Encoding and Classifier\n",
    "\n",
    "## Problem \n",
    "<br>\n",
    "Encoding the following files in a quantum circuit mock_train_set.csv and mock_test_set.csv in at least two different ways (these could be basis, angle, amplitude, kernel or random encoding\n",
    "<br>\n",
    "<br>\n",
    "● Design a variational quantum circuit for each of the encodings, uses the column 4 as the target, this is a binary class 0 and 1.<br>\n",
    "● You must use the data from column0 to column3 for your proposed classifier.<br>\n",
    "● Consider the ansatz you are going to design as a layer and find out how many layers are\n",
    "necessary to reach the best performance. <br>\n",
    "\n",
    "### Analyze and discuss the results\n",
    "\n",
    "Feel free to use existing frameworks (e.g. PennyLane, Qiskit) for creating and training the circuits.<br><br>\n",
    "This PennyLane demo can be useful: Training a quantum circuit with Pytorch,<br>\n",
    "This Quantum Tensorflow tutorial can be useful: Training a quantum circuit with Tensorflow.<br>\n",
    "For the variational circuit, you can try any circuit you want. You can start from one with a layer of RX, RZ and CNOTs.<br>\n",
    "<br>\n",
    "## References\n",
    "* https://pennylane.ai/qml/demos/tutorial_state_preparation.html\n",
    "* https://www.tensorflow.org/quantum/tutorials/mnist\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7528820f",
   "metadata": {},
   "source": [
    "## Clasification Using Amplitude Encoding on 2 Qubits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d2481de7-3eb0-4d54-ae30-a6b8b55637bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f3fb9ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "from pennylane.optimize import NesterovMomentumOptimizer\n",
    "\n",
    "import sys\n",
    "from math import sqrt, pi\n",
    "\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "# supress a warning that is not useful here\n",
    "pd.options.mode.chained_assignment = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "407ceefd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data standardised:\n",
      " [[ 2.78926e+03  3.00000e+00  1.00000e+00  2.00000e+01 -1.00000e+00]\n",
      " [ 4.04001e+03  6.00000e+00  0.00000e+00  1.00000e+00  1.00000e+00]\n",
      " [ 2.93120e+03  4.00000e+00  4.00000e+00  4.00000e+01  1.00000e+00]\n",
      " ...\n",
      " [ 4.18281e+03  0.00000e+00  0.00000e+00  6.50000e+01 -1.00000e+00]\n",
      " [ 3.11375e+03  4.00000e+00  2.00000e+00  1.00000e+00  1.00000e+00]\n",
      " [ 4.56757e+03  4.00000e+00  5.00000e+00  9.00000e+01  1.00000e+00]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data normalized:\n",
      " [[ 0.11203099 -0.04899659 -0.85833249 -0.95544758]\n",
      " [ 0.99674452  1.21091584 -1.35930477 -1.64780089]\n",
      " [ 0.21243174  0.37097422  0.64458432 -0.22665461]\n",
      " ...\n",
      " [ 1.09775359 -1.30890903 -1.35930477  0.68433659]\n",
      " [ 0.34155783  0.37097422 -0.35736022 -1.64780089]\n",
      " [ 1.3699122   0.37097422  1.1455566   1.5953278 ]]\n"
     ]
    }
   ],
   "source": [
    "# sklearn StandardScaler\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html\n",
    "\n",
    "path_train = '/_jupyter/QC/QOSF-challenge-md-2022/task-02/mock_train_set.csv'\n",
    "path_test = '/_jupyter/QC/QOSF-challenge-md-2022/task-02/mock_test_set.csv'\n",
    "\n",
    "df = pd.read_csv(path_train)\n",
    "df_c = df.copy(deep=True)\n",
    "df['1'] = np.log10(df_c['1'])\n",
    "df['2'] = np.log10(df_c['2'])\n",
    "\n",
    "f = lambda x: -1.0 if x==0 else 1.0\n",
    "df['4'] = df_c['4'].map(f)\n",
    "\n",
    "# npdf = df2.to_numpy()\n",
    "npdf = df.to_numpy()\n",
    "data = np.array(npdf)\n",
    "\n",
    "print(\"Train data standardised:\\n\", data)\n",
    "\n",
    "X = data[:, 0:4]\n",
    "Y = data[:, -1]\n",
    "\n",
    "# scale the data using sklearn StandardScaler\n",
    "# std_slc = StandardScaler(with_mean=False)\n",
    "std_slc = StandardScaler(with_mean=True)\n",
    "std_slc.fit(X)\n",
    "X_std = std_slc.transform(X)\n",
    "\n",
    "# normalize data using sklearn StandardScaler\n",
    "normalizer = Normalizer().fit(X_std)  # fit does nothing.\n",
    "X_norm = normalizer.transform(X_std)\n",
    "\n",
    "# features will be the angles vector\n",
    "# features = np.array(X_norm, requires_grad=False)\n",
    "features = np.array(X_std, requires_grad=False)\n",
    "# features = np.array(X, requires_grad=False)\n",
    "print(\"Train data normalized:\\n\", features)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6b43a2",
   "metadata": {},
   "source": [
    "Circuit coding for angle encoding follows pennylane technique, whch is also following the scheme in in Schuld and Petruccione (2018).<br>\n",
    "\"\"We had to also decompose controlled Y-axis rotations into more basic circuits following Nielsen and Chuang (2010).\"\"<br>\n",
    "\n",
    "* https://link.springer.com/book/10.1007/978-3-319-96424-9\n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a9388875",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_qubits = 4\n",
    "num_layers = 2\n",
    "\n",
    "dev = qml.device(\"default.qubit\", wires=num_qubits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200e536c",
   "metadata": {},
   "source": [
    "### test angle encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c55af916",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# circuit that gets trained and optimized\n",
    "@qml.qnode(dev)\n",
    "def circuit(weights, data):\n",
    "\n",
    "    # QAOAEmbedding can take care of both features and weights\n",
    "    # we dont need extra layers\n",
    "    qml.QAOAEmbedding(features=data, weights=weights, wires=range(num_qubits))\n",
    "\n",
    "    return qml.expval(qml.PauliZ(0))\n",
    "\n",
    "draw_flag = 0\n",
    "def variational_classifier(weights, bias, data):\n",
    "    \n",
    "    return circuit(weights, data) + bias\n",
    "\n",
    "# ###############################################################################\n",
    "# standard square loss\n",
    "def square_loss(labels, predictions):\n",
    "    \n",
    "    loss = 0\n",
    "    for l, p in zip(labels, predictions):\n",
    "        loss = loss + (l - p) ** 2\n",
    "\n",
    "    loss = loss / len(labels)\n",
    "    return loss\n",
    "\n",
    "# ###############################################################################\n",
    "# goal: maximize accuracy\n",
    "def accuracy(labels, predictions):\n",
    "\n",
    "    loss = 0\n",
    "    for l, p in zip(labels, predictions):\n",
    "        if abs(l - p) < 1e-5:\n",
    "            loss = loss + 1\n",
    "    loss = loss / len(labels)\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "def cost(weights, bias, features, labels):\n",
    "    \n",
    "    predictions = [variational_classifier(weights, bias, f) for f in features]\n",
    "    return square_loss(labels, predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a59fb6d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(with_mean=False)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ####################################################################\n",
    "# split train data set in train and evaluation\n",
    "\n",
    "np.random.seed(0)\n",
    "num_data = len(Y)\n",
    "\n",
    "num_train = int(0.75 * num_data)\n",
    "index = np.random.permutation(range(num_data))\n",
    "\n",
    "feats_train = features[index[:num_train]]\n",
    "Y_train = Y[index[:num_train]]\n",
    "\n",
    "feats_val = features[index[num_train:]]\n",
    "Y_val = Y[index[num_train:]]\n",
    "\n",
    "# We need these later for plotting\n",
    "X_train = X[index[:num_train]]\n",
    "X_val = X[index[num_train:]]\n",
    "\n",
    "\n",
    "# ##################################################################\n",
    "# Load the test dataset and apply same transformations \n",
    "# as we did with the train dataset.\n",
    "df_test = pd.read_csv(path_test)\n",
    "df_test_c = df_test.copy(deep=True)\n",
    "df_test['1'] = np.log10(df_test_c['1'])\n",
    "df_test['2'] = np.log10(df_test_c['2'])\n",
    "\n",
    "f = lambda x: -1.0 if x==0 else 1.0\n",
    "df_test['4'] = df_test_c['4'].map(f)\n",
    "data_test = df_test.to_numpy()\n",
    "\n",
    "X_test_ini = data_test[:, 0:4]\n",
    "Y_test = data_test[:, -1]\n",
    "\n",
    "# scale data using sklearn StandardScaler\n",
    "std_slc = StandardScaler(with_mean=False)\n",
    "std_slc.fit(X_test_ini)\n",
    "X_test_std = std_slc.transform(X_test_ini)\n",
    "\n",
    "# normalize data using sklearn StandardScaler\n",
    "normalizer = Normalizer().fit(X_test_std)  # fit does nothing.\n",
    "X_test_norm = normalizer.transform(X_test_std)\n",
    "\n",
    "# convert to a pennylane numpy array\n",
    "X_test = np.array(X_test_norm, requires_grad=False)\n",
    "\n",
    "# #########################################################################\n",
    "# \n",
    "def test_accuracy(weights, bias):\n",
    "\n",
    "    # apply the variational clasifier circuit on test dataset\n",
    "    # using the learned weights\n",
    "    predictions_test = [np.sign(variational_classifier(weights, bias, f)) for f in X_test]\n",
    "\n",
    "    return accuracy(Y_test, predictions_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "544af8f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:     1 | Cost: 1.8212823 | Acc train: 0.5111111 | Acc validation: 0.5600000 | Acc test: 0.4833333 \n",
      "Iter:     2 | Cost: 1.0296806 | Acc train: 0.5333333 | Acc validation: 0.5600000 | Acc test: 0.5833333 \n",
      "Iter:     3 | Cost: 1.1889821 | Acc train: 0.5111111 | Acc validation: 0.4133333 | Acc test: 0.5166667 \n",
      "Iter:     4 | Cost: 1.1028200 | Acc train: 0.4666667 | Acc validation: 0.4800000 | Acc test: 0.8416667 \n",
      "Iter:     5 | Cost: 1.3055322 | Acc train: 0.5333333 | Acc validation: 0.5333333 | Acc test: 0.4833333 \n",
      "Iter:     6 | Cost: 1.0441662 | Acc train: 0.5200000 | Acc validation: 0.5466667 | Acc test: 0.4833333 \n",
      "Iter:     7 | Cost: 1.7034816 | Acc train: 0.5111111 | Acc validation: 0.5600000 | Acc test: 0.4833333 \n",
      "Iter:     8 | Cost: 1.4302438 | Acc train: 0.4977778 | Acc validation: 0.6000000 | Acc test: 0.4833333 \n",
      "Iter:     9 | Cost: 1.6264451 | Acc train: 0.5111111 | Acc validation: 0.5600000 | Acc test: 0.4833333 \n",
      "Iter:    10 | Cost: 1.1917331 | Acc train: 0.4977778 | Acc validation: 0.4933333 | Acc test: 0.5500000 \n",
      "Iter:    11 | Cost: 1.1262868 | Acc train: 0.5333333 | Acc validation: 0.6000000 | Acc test: 0.4833333 \n",
      "Iter:    12 | Cost: 1.4390357 | Acc train: 0.5244444 | Acc validation: 0.5333333 | Acc test: 0.4833333 \n",
      "Iter:    13 | Cost: 1.1238920 | Acc train: 0.5200000 | Acc validation: 0.5333333 | Acc test: 0.4833333 \n",
      "Iter:    14 | Cost: 1.2766489 | Acc train: 0.5333333 | Acc validation: 0.5466667 | Acc test: 0.4833333 \n",
      "Iter:    15 | Cost: 1.1732430 | Acc train: 0.5333333 | Acc validation: 0.5733333 | Acc test: 0.1500000 \n",
      "Iter:    16 | Cost: 1.0400372 | Acc train: 0.5155556 | Acc validation: 0.5333333 | Acc test: 0.4833333 \n",
      "Iter:    17 | Cost: 1.0921857 | Acc train: 0.5422222 | Acc validation: 0.5333333 | Acc test: 0.4833333 \n",
      "Iter:    18 | Cost: 1.5392212 | Acc train: 0.5111111 | Acc validation: 0.5600000 | Acc test: 0.4833333 \n",
      "Iter:    19 | Cost: 1.2724874 | Acc train: 0.4888889 | Acc validation: 0.4533333 | Acc test: 0.5166667 \n",
      "Iter:    20 | Cost: 1.3594615 | Acc train: 0.5111111 | Acc validation: 0.5600000 | Acc test: 0.4833333 \n",
      "Iter:    21 | Cost: 1.0560000 | Acc train: 0.4888889 | Acc validation: 0.4533333 | Acc test: 0.4833333 \n",
      "Iter:    22 | Cost: 1.1485792 | Acc train: 0.5333333 | Acc validation: 0.5733333 | Acc test: 0.4333333 \n",
      "Iter:    23 | Cost: 1.3044253 | Acc train: 0.4888889 | Acc validation: 0.4400000 | Acc test: 0.5166667 \n",
      "Iter:    24 | Cost: 0.9393825 | Acc train: 0.6400000 | Acc validation: 0.5466667 | Acc test: 0.5166667 \n",
      "Iter:    25 | Cost: 0.9198119 | Acc train: 0.5777778 | Acc validation: 0.5600000 | Acc test: 0.5166667 \n",
      "Iter:    26 | Cost: 0.9945601 | Acc train: 0.5688889 | Acc validation: 0.5866667 | Acc test: 0.5166667 \n",
      "Iter:    27 | Cost: 2.0787553 | Acc train: 0.5111111 | Acc validation: 0.5600000 | Acc test: 0.4833333 \n",
      "Iter:    28 | Cost: 1.4082797 | Acc train: 0.4800000 | Acc validation: 0.5066667 | Acc test: 0.5666667 \n",
      "Iter:    29 | Cost: 1.0882576 | Acc train: 0.4755556 | Acc validation: 0.5333333 | Acc test: 0.3750000 \n",
      "Iter:    30 | Cost: 1.5363857 | Acc train: 0.5288889 | Acc validation: 0.5600000 | Acc test: 0.4833333 \n",
      "Iter:    31 | Cost: 1.4144047 | Acc train: 0.4888889 | Acc validation: 0.4400000 | Acc test: 0.5166667 \n",
      "Iter:    32 | Cost: 1.1862842 | Acc train: 0.5111111 | Acc validation: 0.4400000 | Acc test: 0.4916667 \n",
      "Iter:    33 | Cost: 1.1027787 | Acc train: 0.5688889 | Acc validation: 0.5733333 | Acc test: 0.1583333 \n",
      "Iter:    34 | Cost: 1.1921312 | Acc train: 0.5244444 | Acc validation: 0.5733333 | Acc test: 0.2416667 \n",
      "Iter:    35 | Cost: 1.2039258 | Acc train: 0.4844444 | Acc validation: 0.4000000 | Acc test: 0.5166667 \n",
      "Iter:    36 | Cost: 1.0639905 | Acc train: 0.4977778 | Acc validation: 0.5066667 | Acc test: 0.5166667 \n",
      "Iter:    37 | Cost: 1.7457066 | Acc train: 0.5111111 | Acc validation: 0.4133333 | Acc test: 0.5166667 \n",
      "Iter:    38 | Cost: 1.7895430 | Acc train: 0.5155556 | Acc validation: 0.5600000 | Acc test: 0.3583333 \n",
      "Iter:    39 | Cost: 1.2623710 | Acc train: 0.4666667 | Acc validation: 0.4933333 | Acc test: 0.6916667 \n",
      "Iter:    40 | Cost: 1.0964948 | Acc train: 0.4755556 | Acc validation: 0.5466667 | Acc test: 0.4833333 \n",
      "Iter:    41 | Cost: 1.5966690 | Acc train: 0.4888889 | Acc validation: 0.4400000 | Acc test: 0.5166667 \n",
      "Iter:    42 | Cost: 1.7738550 | Acc train: 0.5111111 | Acc validation: 0.5600000 | Acc test: 0.4833333 \n",
      "Iter:    43 | Cost: 1.7760422 | Acc train: 0.4933333 | Acc validation: 0.5200000 | Acc test: 0.2333333 \n",
      "Iter:    44 | Cost: 1.1796012 | Acc train: 0.5200000 | Acc validation: 0.5066667 | Acc test: 0.4833333 \n",
      "Iter:    45 | Cost: 1.0705754 | Acc train: 0.5155556 | Acc validation: 0.4800000 | Acc test: 0.4833333 \n",
      "Iter:    46 | Cost: 1.2311964 | Acc train: 0.4888889 | Acc validation: 0.5866667 | Acc test: 0.3083333 \n",
      "Iter:    47 | Cost: 1.3816475 | Acc train: 0.4977778 | Acc validation: 0.4266667 | Acc test: 0.5250000 \n",
      "Iter:    48 | Cost: 1.2114122 | Acc train: 0.4888889 | Acc validation: 0.5466667 | Acc test: 0.3083333 \n",
      "Iter:    49 | Cost: 1.3526174 | Acc train: 0.4977778 | Acc validation: 0.4266667 | Acc test: 0.5166667 \n",
      "Iter:    50 | Cost: 1.5771075 | Acc train: 0.5022222 | Acc validation: 0.5733333 | Acc test: 0.4833333 \n",
      "Iter:    51 | Cost: 1.1104066 | Acc train: 0.5600000 | Acc validation: 0.5600000 | Acc test: 0.4083333 \n",
      "Iter:    52 | Cost: 1.1916235 | Acc train: 0.4800000 | Acc validation: 0.4666667 | Acc test: 0.5166667 \n",
      "Iter:    53 | Cost: 1.3239810 | Acc train: 0.5333333 | Acc validation: 0.5733333 | Acc test: 0.4833333 \n",
      "Iter:    54 | Cost: 1.2015237 | Acc train: 0.4888889 | Acc validation: 0.4400000 | Acc test: 0.5166667 \n",
      "Iter:    55 | Cost: 1.7251109 | Acc train: 0.5066667 | Acc validation: 0.5600000 | Acc test: 0.4833333 \n",
      "Iter:    56 | Cost: 1.2828127 | Acc train: 0.5022222 | Acc validation: 0.5066667 | Acc test: 0.1750000 \n",
      "Iter:    57 | Cost: 1.1993528 | Acc train: 0.4933333 | Acc validation: 0.4933333 | Acc test: 0.3916667 \n",
      "Iter:    58 | Cost: 1.2320377 | Acc train: 0.5066667 | Acc validation: 0.4533333 | Acc test: 0.3250000 \n",
      "Iter:    59 | Cost: 1.0993380 | Acc train: 0.4755556 | Acc validation: 0.5066667 | Acc test: 0.4833333 \n",
      "Iter:    60 | Cost: 2.5181394 | Acc train: 0.4888889 | Acc validation: 0.4400000 | Acc test: 0.5166667 \n",
      "Iter:    61 | Cost: 1.1420128 | Acc train: 0.5155556 | Acc validation: 0.5466667 | Acc test: 0.4333333 \n",
      "Iter:    62 | Cost: 1.2980446 | Acc train: 0.4800000 | Acc validation: 0.5600000 | Acc test: 0.4833333 \n",
      "Iter:    63 | Cost: 1.1029950 | Acc train: 0.5333333 | Acc validation: 0.6133333 | Acc test: 0.4833333 \n",
      "Iter:    64 | Cost: 1.2020402 | Acc train: 0.5333333 | Acc validation: 0.5200000 | Acc test: 0.5166667 \n",
      "Iter:    65 | Cost: 1.1712458 | Acc train: 0.5155556 | Acc validation: 0.4800000 | Acc test: 0.5166667 \n",
      "Iter:    66 | Cost: 1.1011086 | Acc train: 0.5111111 | Acc validation: 0.5066667 | Acc test: 0.5166667 \n",
      "Iter:    67 | Cost: 1.1561413 | Acc train: 0.5066667 | Acc validation: 0.5333333 | Acc test: 0.7083333 \n",
      "Iter:    68 | Cost: 1.0076695 | Acc train: 0.5155556 | Acc validation: 0.5733333 | Acc test: 0.5916667 \n",
      "Iter:    69 | Cost: 1.2204005 | Acc train: 0.4933333 | Acc validation: 0.4400000 | Acc test: 0.5166667 \n",
      "Iter:    70 | Cost: 1.1501528 | Acc train: 0.5111111 | Acc validation: 0.5600000 | Acc test: 0.4833333 \n",
      "Iter:    71 | Cost: 1.4432692 | Acc train: 0.4888889 | Acc validation: 0.4400000 | Acc test: 0.5166667 \n",
      "Iter:    72 | Cost: 1.0631592 | Acc train: 0.5022222 | Acc validation: 0.5200000 | Acc test: 0.5666667 \n",
      "Iter:    73 | Cost: 1.1314991 | Acc train: 0.5022222 | Acc validation: 0.4400000 | Acc test: 0.5916667 \n",
      "Iter:    74 | Cost: 1.3228959 | Acc train: 0.4977778 | Acc validation: 0.4533333 | Acc test: 0.5166667 \n",
      "Iter:    75 | Cost: 1.0674827 | Acc train: 0.5422222 | Acc validation: 0.4666667 | Acc test: 0.5833333 \n",
      "Iter:    76 | Cost: 1.1377053 | Acc train: 0.5022222 | Acc validation: 0.4666667 | Acc test: 0.5166667 \n",
      "Iter:    77 | Cost: 1.0893657 | Acc train: 0.5466667 | Acc validation: 0.5600000 | Acc test: 0.4833333 \n",
      "Iter:    78 | Cost: 1.0894671 | Acc train: 0.5066667 | Acc validation: 0.5466667 | Acc test: 0.2583333 \n",
      "Iter:    79 | Cost: 1.1394349 | Acc train: 0.5555556 | Acc validation: 0.5333333 | Acc test: 0.4833333 \n",
      "Iter:    80 | Cost: 1.0157253 | Acc train: 0.5155556 | Acc validation: 0.5600000 | Acc test: 0.2750000 \n",
      "Iter:    81 | Cost: 0.9806579 | Acc train: 0.5600000 | Acc validation: 0.5733333 | Acc test: 0.4750000 \n",
      "Iter:    82 | Cost: 0.9664215 | Acc train: 0.5511111 | Acc validation: 0.5733333 | Acc test: 0.5000000 \n",
      "Iter:    83 | Cost: 0.9550135 | Acc train: 0.5511111 | Acc validation: 0.5733333 | Acc test: 0.6666667 \n",
      "Iter:    84 | Cost: 1.0533295 | Acc train: 0.6222222 | Acc validation: 0.5200000 | Acc test: 0.5166667 \n",
      "Iter:    85 | Cost: 1.1303694 | Acc train: 0.6044444 | Acc validation: 0.5200000 | Acc test: 0.5166667 \n",
      "Iter:    86 | Cost: 1.1213034 | Acc train: 0.5244444 | Acc validation: 0.6000000 | Acc test: 0.7666667 \n",
      "Iter:    87 | Cost: 1.0395705 | Acc train: 0.5422222 | Acc validation: 0.5733333 | Acc test: 0.5166667 \n",
      "Iter:    88 | Cost: 1.1002621 | Acc train: 0.5688889 | Acc validation: 0.5200000 | Acc test: 0.5166667 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_11054/1849046360.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m# Compute predictions on train and validation set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mpredictions_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariational_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeats_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0mpredictions_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariational_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeats_val\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_11054/1849046360.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m# Compute predictions on train and validation set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mpredictions_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariational_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeats_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0mpredictions_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariational_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeats_val\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_11054/4086667532.py\u001b[0m in \u001b[0;36mvariational_classifier\u001b[0;34m(weights, bias, data)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# qml.draw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcircuit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# ###############################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pennylane/qnode.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape_cached\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0musing_custom_cache\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhash\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m         res = qml.execute(\n\u001b[0m\u001b[1;32m    561\u001b[0m             \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtape\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m             \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pennylane/interfaces/batch/__init__.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(tapes, device, gradient_fn, interface, mode, gradient_kwargs, cache, cachesize, max_diff, override_shots, expand_fn, max_expansion, device_batch_transform)\u001b[0m\n\u001b[1;32m    340\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgradient_fn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"backprop\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minterface\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         return batch_fn(\n\u001b[0;32m--> 342\u001b[0;31m             \u001b[0mcache_execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_execute\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tuple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexpand_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m         )\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pennylane/interfaces/batch/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(tapes, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0;31m# execute all unique tapes that do not exist in the cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexecution_tapes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0mfinal_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pennylane/interfaces/batch/__init__.py\u001b[0m in \u001b[0;36mfn\u001b[0;34m(tapes, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=function-redefined\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0mtapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mexpand_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtape\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtapes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moriginal_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/contextlib.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recreate_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pennylane/_qubit_device.py\u001b[0m in \u001b[0;36mbatch_execute\u001b[0;34m(self, circuits)\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcircuit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m             \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pennylane/_qubit_device.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, circuit, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;31m# apply all circuit operations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcircuit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moperations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrotations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcircuit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiagonalizing_gates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;31m# generate computational basis samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pennylane/devices/default_qubit.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, operations, rotations, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_basis_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwires\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_operation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;31m# store the pre-rotated state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pennylane/devices/default_qubit.py\u001b[0m in \u001b[0;36m_apply_operation\u001b[0;34m(self, state, operation)\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwires\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0;31m# Einsum is faster for small gates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_unitary_einsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwires\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_unitary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwires\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pennylane/devices/default_qubit.py\u001b[0m in \u001b[0;36m_apply_unitary_einsum\u001b[0;34m(self, state, mat, wires)\u001b[0m\n\u001b[1;32m    728\u001b[0m         \u001b[0mdevice_wires\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_wires\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwires\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m         \u001b[0mmat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_wires\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mC_DTYPE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m         \u001b[0;31m# Tensor indices of the quantum state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pennylane/numpy/wrapper.py\u001b[0m in \u001b[0;36m_wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0mtensor_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"requires_grad\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"requires_grad\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0mtensor_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtensor_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pennylane/numpy/wrapper.py\u001b[0m in \u001b[0;36mextract_tensors\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;31m# as NumPy arrays are not Sequences.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mextract_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pennylane/numpy/wrapper.py\u001b[0m in \u001b[0;36mextract_tensors\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;31m# as NumPy arrays are not Sequences.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mextract_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pennylane/numpy/wrapper.py\u001b[0m in \u001b[0;36mextract_tensors\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m# If the item is a tensor, return it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0;31m# If the item is a sequence, recursively look through its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m# elements for tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/abc.py\u001b[0m in \u001b[0;36m__instancecheck__\u001b[0;34m(cls, instance)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m__instancecheck__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;34m\"\"\"Override for isinstance(instance, cls).\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_abc_instancecheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m__subclasscheck__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubclass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "shape = qml.QAOAEmbedding.shape(n_layers=num_layers, n_wires=num_qubits)\n",
    "weights_init = np.random.random(shape)\n",
    "bias_init = np.array(0.0, requires_grad=True)\n",
    "\n",
    "\n",
    "opt = NesterovMomentumOptimizer(0.01) \n",
    "# opt = NesterovMomentumOptimizer(0.1) # ok\n",
    "# opt = NesterovMomentumOptimizer(0.5)\n",
    "# batch_size = 5\n",
    "# batch_size = 15\n",
    "# batch_size = 20\n",
    "batch_size = 10\n",
    "\n",
    "\n",
    "# train the variational classifier\n",
    "weights = weights_init\n",
    "bias = bias_init\n",
    "steps = 90 # acc: 0.89\n",
    "# steps = 5\n",
    "\n",
    "for it in range(steps):\n",
    "\n",
    "    # Update the weights by one optimizer step\n",
    "    batch_index = np.random.randint(0, num_train, (batch_size,))\n",
    "    feats_train_batch = feats_train[batch_index]\n",
    "    Y_train_batch = Y_train[batch_index]\n",
    "    weights, bias, _, _ = opt.step(cost, weights, bias, feats_train_batch, Y_train_batch)\n",
    "\n",
    "    # Compute predictions on train and validation set\n",
    "    predictions_train = [np.sign(variational_classifier(weights, bias, f)) for f in feats_train]\n",
    "    predictions_val = [np.sign(variational_classifier(weights, bias, f)) for f in feats_val]\n",
    "\n",
    "    # Compute accuracy on train and validation set\n",
    "    acc_train = accuracy(Y_train, predictions_train)\n",
    "    acc_val = accuracy(Y_val, predictions_val)\n",
    "\n",
    "    acc_test = test_accuracy(weights, bias)\n",
    "\n",
    "    # print(\n",
    "    #     \"Iter: {:5d} | Cost: {:0.7f} | Acc train: {:0.7f} | Acc validation: {:0.7f} \"\n",
    "    #     \"\".format(it + 1, cost(weights, bias, features, Y), acc_train, acc_val)\n",
    "    # )\n",
    "\n",
    "    print(\n",
    "        \"Iter: {:5d} | Cost: {:0.7f} | Acc train: {:0.7f} | Acc validation: {:0.7f} | Acc test: {:0.7f} \"\n",
    "        \"\".format(it + 1, cost(weights, bias, features, Y), acc_train, acc_val, acc_test)\n",
    "    )\n",
    "\n",
    "\n",
    "    if acc_train >= 0.93 and acc_val >= 0.93:\n",
    "        # early stop\n",
    "        break\n",
    "\n",
    "print('bias: ', bias)    \n",
    "print('weights:\\n', weights)\n",
    "# np.save('/_jupyter/QC/QOSF-challenge-md-2022/task-02/temp-data/variational_classifier/data/mock_train_numpy_wights_02.npy', weights, allow_pickle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f55127",
   "metadata": {},
   "source": [
    "Load the test dataset and apply same transformations as we did with the train dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98d9a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "acc_test = test_accuracy(weights, bias)\n",
    "print('Accuracy on test data: {:0.4f}'.format(acc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fad434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # We can plot the continuous output of the variational classifier for the first two dimensions of the data set.\n",
    "# plt.figure()\n",
    "# cm = plt.cm.RdBu\n",
    "\n",
    "# # make data for decision regions\n",
    "# xx, yy = np.meshgrid(np.linspace(0.0, 1.5, 300), np.linspace(0.0, 1.5, 300))\n",
    "# X_grid = [np.array([x, y]) for x, y in zip(xx.flatten(), yy.flatten())]\n",
    "\n",
    "# pd.DataFrame(xx).shape\n",
    "# pd.DataFrame(yy).shape\n",
    "# pd.DataFrame(X_grid).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47506f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # # preprocess grid points like data inputs above\n",
    "# # padding = 0.3 * np.ones((len(X_grid), 1))\n",
    "# # X_grid = np.c_[np.c_[X_grid, padding], np.zeros((len(X_grid), 1))]  # pad each input\n",
    "\n",
    "# # normalization = np.sqrt(np.sum(X_grid ** 2, -1))\n",
    "# # X_grid = (X_grid.T / normalization).T  # normalize each input\n",
    "\n",
    "# # features_grid = np.array(\n",
    "# #     [get_angles(x) for x in X_grid]\n",
    "# # )  # angles for state preparation are new features\n",
    "\n",
    "# X_grid = X_norm\n",
    "# features_grid = X_grid\n",
    "# predictions_grid = [variational_classifier(weights, bias, f) for f in features_grid]\n",
    "# # Z = np.reshape(predictions_grid, xx.shape)\n",
    "# Z = predictions_grid \n",
    "\n",
    "# # plot decision regions\n",
    "# cnt = plt.contourf(\n",
    "#     xx, yy, Z, levels=np.arange(-1, 1.1, 0.1), cmap=cm, alpha=0.8, extend=\"both\"\n",
    "# )\n",
    "# plt.contour(\n",
    "#     xx, yy, Z, levels=[0.0], colors=(\"black\",), linestyles=(\"--\",), linewidths=(0.8,)\n",
    "# )\n",
    "# plt.colorbar(cnt, ticks=[-1, 0, 1])\n",
    "\n",
    "# # plot data\n",
    "# plt.scatter(\n",
    "#     X_train[:, 0][Y_train == 1],\n",
    "#     X_train[:, 1][Y_train == 1],\n",
    "#     c=\"b\",\n",
    "#     marker=\"o\",\n",
    "#     edgecolors=\"k\",\n",
    "#     label=\"class 1 train\",\n",
    "# )\n",
    "# plt.scatter(\n",
    "#     X_val[:, 0][Y_val == 1],\n",
    "#     X_val[:, 1][Y_val == 1],\n",
    "#     c=\"b\",\n",
    "#     marker=\"^\",\n",
    "#     edgecolors=\"k\",\n",
    "#     label=\"class 1 validation\",\n",
    "# )\n",
    "# # plt.scatter(\n",
    "# #     X_train[:, 0][Y_train == -1],\n",
    "# #     X_train[:, 1][Y_train == -1],\n",
    "# #     c=\"r\",\n",
    "# #     marker=\"o\",\n",
    "# #     edgecolors=\"k\",\n",
    "# #     label=\"class -1 train\",\n",
    "# # )\n",
    "# # plt.scatter(\n",
    "# #     X_val[:, 0][Y_val == -1],\n",
    "# #     X_val[:, 1][Y_val == -1],\n",
    "# #     c=\"r\",\n",
    "# #     marker=\"^\",\n",
    "# #     edgecolors=\"k\",\n",
    "# #     label=\"class -1 validation\",\n",
    "# # )\n",
    "\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17a310c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
