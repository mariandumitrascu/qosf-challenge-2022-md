{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ccfe335-e640-4b2c-b933-cba2bd38fab7",
   "metadata": {},
   "source": [
    "# Task 2 Encoding and Classifier\n",
    "\n",
    "## Problem \n",
    "<br>\n",
    "Encoding the following files in a quantum circuit mock_train_set.csv and mock_test_set.csv in at least two different ways (these could be basis, angle, amplitude, kernel or random encoding\n",
    "<br>\n",
    "<br>\n",
    "● Design a variational quantum circuit for each of the encodings, uses the column 4 as the target, this is a binary class 0 and 1.<br>\n",
    "● You must use the data from column0 to column3 for your proposed classifier.<br>\n",
    "● Consider the ansatz you are going to design as a layer and find out how many layers are\n",
    "necessary to reach the best performance. <br>\n",
    "\n",
    "### Analyze and discuss the results\n",
    "\n",
    "Feel free to use existing frameworks (e.g. PennyLane, Qiskit) for creating and training the circuits.<br><br>\n",
    "This PennyLane demo can be useful: Training a quantum circuit with Pytorch,<br>\n",
    "This Quantum Tensorflow tutorial can be useful: Training a quantum circuit with Tensorflow.<br>\n",
    "For the variational circuit, you can try any circuit you want. You can start from one with a layer of RX, RZ and CNOTs.<br>\n",
    "<br>\n",
    "## References\n",
    "* https://pennylane.ai/qml/demos/tutorial_state_preparation.html\n",
    "* https://www.tensorflow.org/quantum/tutorials/mnist\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7528820f",
   "metadata": {},
   "source": [
    "## Clasification Using Amplitude Encoding on 2 Qubits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2481de7-3eb0-4d54-ae30-a6b8b55637bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3fb9ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "from pennylane.optimize import NesterovMomentumOptimizer\n",
    "\n",
    "import sys\n",
    "from math import sqrt, pi\n",
    "\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "# supress a warning that is not useful here\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "# references:\n",
    "# pandas dataframe:\n",
    "# https://pandas.pydata.org/docs/reference/frame.html\n",
    "# numpy math routines:\n",
    "# https://numpy.org/doc/stable/reference/routines.math.html\n",
    "# pandas quick shortcuts:\n",
    "# https://www.listendata.com/2017/12/python-pandas-tutorial.html\n",
    "# https://www.listendata.com/2019/06/pandas-read-csv.html#Example-How-to-read-CSV-file-without-using-Pandas-package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "407ceefd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data standardised:\n",
      " [[ 2.78926e+03  3.00000e+00  1.00000e+00  2.00000e+01 -1.00000e+00]\n",
      " [ 4.04001e+03  6.00000e+00  0.00000e+00  1.00000e+00  1.00000e+00]\n",
      " [ 2.93120e+03  4.00000e+00  4.00000e+00  4.00000e+01  1.00000e+00]\n",
      " ...\n",
      " [ 4.18281e+03  0.00000e+00  0.00000e+00  6.50000e+01 -1.00000e+00]\n",
      " [ 3.11375e+03  4.00000e+00  2.00000e+00  1.00000e+00  1.00000e+00]\n",
      " [ 4.56757e+03  4.00000e+00  5.00000e+00  9.00000e+01  1.00000e+00]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StandardScaler(with_mean=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data normalized:\n",
      " [[0.78842549 0.50347726 0.20019498 0.29123507]\n",
      " [0.7500201  0.66134589 0.         0.00956384]\n",
      " [0.56936298 0.46130771 0.55028199 0.40026331]\n",
      " ...\n",
      " [0.78066018 0.         0.         0.62495574]\n",
      " [0.74765323 0.57024753 0.34011673 0.01236968]\n",
      " [0.5870369  0.30522994 0.45512608 0.5958881 ]]\n"
     ]
    }
   ],
   "source": [
    "# sklearn StandardScaler\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html\n",
    "\n",
    "path_train = '/_jupyter/QC/QOSF-challenge-md-2022/task-02/mock_train_set.csv'\n",
    "path_test = '/_jupyter/QC/QOSF-challenge-md-2022/task-02/mock_test_set.csv'\n",
    "\n",
    "df = pd.read_csv(path_train)\n",
    "df_c = df.copy(deep=True)\n",
    "df['1'] = np.log10(df_c['1'])\n",
    "df['2'] = np.log10(df_c['2'])\n",
    "\n",
    "f = lambda x: -1.0 if x==0 else 1.0\n",
    "df['4'] = df_c['4'].map(f)\n",
    "\n",
    "# npdf = df2.to_numpy()\n",
    "npdf = df.to_numpy()\n",
    "data = np.array(npdf)\n",
    "\n",
    "print(\"Train data standardised:\\n\", data)\n",
    "\n",
    "X = data[:, 0:4]\n",
    "Y = data[:, -1]\n",
    "\n",
    "# scale the data using sklearn StandardScaler\n",
    "std_slc = StandardScaler(with_mean=False)\n",
    "std_slc.fit(X)\n",
    "X_std = std_slc.transform(X)\n",
    "\n",
    "# normalize data using sklearn StandardScaler\n",
    "normalizer = Normalizer().fit(X_std)  # fit does nothing.\n",
    "X_norm = normalizer.transform(X_std)\n",
    "\n",
    "\n",
    "# features will be applitudes vector\n",
    "features = np.array(X_norm, requires_grad=False)\n",
    "print(\"Train data normalized:\\n\", features)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6b43a2",
   "metadata": {},
   "source": [
    "Circuit coding for angle encoding follows pennylane technique, whch is also following the scheme in in Schuld and Petruccione (2018).<br>\n",
    "\"\"We had to also decompose controlled Y-axis rotations into more basic circuits following Nielsen and Chuang (2010).\"\"<br>\n",
    "\n",
    "* https://link.springer.com/book/10.1007/978-3-319-96424-9\n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9388875",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_qubits = 2\n",
    "num_layers = 6\n",
    "\n",
    "dev = qml.device(\"default.qubit\", wires=num_qubits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200e536c",
   "metadata": {},
   "source": [
    "### test angle encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c55af916",
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer(W):\n",
    "    qml.Rot(W[0, 0], W[0, 1], W[0, 2], wires=0)\n",
    "    qml.Rot(W[1, 0], W[1, 1], W[1, 2], wires=1)\n",
    "    qml.CNOT(wires=[0, 1])\n",
    "\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def circuit(weights, data):\n",
    "\n",
    "    qml.AmplitudeEmbedding(features=data, wires=range(num_qubits))\n",
    "\n",
    "    for W in weights:\n",
    "        layer(W)\n",
    "\n",
    "    return qml.expval(qml.PauliZ(0))\n",
    "\n",
    "draw_flag = 0\n",
    "def variational_classifier(weights, bias, data):\n",
    "    \n",
    "    global draw_flag\n",
    "\n",
    "    if draw_flag:\n",
    "        draw_flag=0\n",
    "        # qml.draw\n",
    "\n",
    "    return circuit(weights, data) + bias\n",
    "\n",
    "# ###############################################################################\n",
    "# standard square loss\n",
    "def square_loss(labels, predictions):\n",
    "    \n",
    "    loss = 0\n",
    "    for l, p in zip(labels, predictions):\n",
    "        loss = loss + (l - p) ** 2\n",
    "\n",
    "    loss = loss / len(labels)\n",
    "    return loss\n",
    "\n",
    "# ###############################################################################\n",
    "# goal: maximize accuracy\n",
    "def accuracy(labels, predictions):\n",
    "\n",
    "    loss = 0\n",
    "    for l, p in zip(labels, predictions):\n",
    "        if abs(l - p) < 1e-5:\n",
    "            loss = loss + 1\n",
    "    loss = loss / len(labels)\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "def cost(weights, bias, features, labels):\n",
    "    \n",
    "    predictions = [variational_classifier(weights, bias, f) for f in features]\n",
    "    return square_loss(labels, predictions)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb3976f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.figure()\n",
    "# plt.scatter(X[:, 0][Y == 1], X[:, 1][Y == 1], c=\"b\", marker=\"o\", edgecolors=\"k\")\n",
    "# plt.scatter(X[:, 0][Y == -1], X[:, 1][Y == -1], c=\"r\", marker=\"o\", edgecolors=\"k\")\n",
    "# plt.title(\"Original data\")\n",
    "# plt.show()\n",
    "\n",
    "# plt.figure()\n",
    "# plt.scatter(X[:, 0][Y == 1], X[:, 2][Y == 1], c=\"b\", marker=\"o\", edgecolors=\"k\")\n",
    "# plt.scatter(X[:, 0][Y == -1], X[:, 2][Y == -1], c=\"r\", marker=\"o\", edgecolors=\"k\")\n",
    "# plt.title(\"Original data\")\n",
    "# plt.show()\n",
    "\n",
    "# plt.figure()\n",
    "# plt.scatter(X[:, 0][Y == 1], X[:, 3][Y == 1], c=\"b\", marker=\"o\", edgecolors=\"k\")\n",
    "# plt.scatter(X[:, 0][Y == -1], X[:, 3][Y == -1], c=\"r\", marker=\"o\", edgecolors=\"k\")\n",
    "# plt.title(\"Original data\")\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# plt.figure()\n",
    "# plt.scatter(X[:, 1][Y == 1], X[:, 2][Y == 1], c=\"b\", marker=\"o\", edgecolors=\"k\")\n",
    "# plt.scatter(X[:, 1][Y == -1], X[:, 2][Y == -1], c=\"r\", marker=\"o\", edgecolors=\"k\")\n",
    "# plt.title(\"Original data\")\n",
    "# plt.show()\n",
    "\n",
    "# plt.figure()\n",
    "# plt.scatter(X[:, 1][Y == 1], X[:, 3][Y == 1], c=\"b\", marker=\"o\", edgecolors=\"k\")\n",
    "# plt.scatter(X[:, 1][Y == -1], X[:, 3][Y == -1], c=\"r\", marker=\"o\", edgecolors=\"k\")\n",
    "# plt.title(\"Original data\")\n",
    "# plt.show()\n",
    "\n",
    "# plt.figure()\n",
    "# plt.scatter(X[:, 2][Y == 1], X[:, 3][Y == 1], c=\"b\", marker=\"o\", edgecolors=\"k\")\n",
    "# plt.scatter(X[:, 2][Y == -1], X[:, 3][Y == -1], c=\"r\", marker=\"o\", edgecolors=\"k\")\n",
    "# plt.title(\"Original data\")\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfca1b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "# dim1 = 0\n",
    "# dim2 = 2\n",
    "# plt.scatter(\n",
    "#     X_norm[:, dim1][Y == 1], X_norm[:, dim2][Y == 1], c=\"b\", marker=\"o\", edgecolors=\"k\"\n",
    "# )\n",
    "# plt.scatter(\n",
    "#     X_norm[:, dim1][Y == -1], X_norm[:, dim2][Y == -1], c=\"r\", marker=\"o\", edgecolors=\"k\"\n",
    "# )\n",
    "# plt.title(\"Padded and normalised data (dims {} and {})\".format(dim1, dim2))\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# plt.figure()\n",
    "# dim1 = 0\n",
    "# dim2 = 1\n",
    "# plt.scatter(\n",
    "#     features[:, dim1][Y == 1], features[:, dim2][Y == 1], c=\"b\", marker=\"o\", edgecolors=\"k\"\n",
    "# )\n",
    "# plt.scatter(\n",
    "#     features[:, dim1][Y == -1], features[:, dim2][Y == -1], c=\"r\", marker=\"o\", edgecolors=\"k\"\n",
    "# )\n",
    "# plt.title(\"Feature vectors (dims {} and {})\".format(dim1, dim2))\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# plt.figure()\n",
    "# dim1 = 1\n",
    "# dim2 = 2\n",
    "# plt.scatter(\n",
    "#     features[:, dim1][Y == 1], features[:, dim2][Y == 1], c=\"b\", marker=\"o\", edgecolors=\"k\"\n",
    "# )\n",
    "# plt.scatter(\n",
    "#     features[:, dim1][Y == -1], features[:, dim2][Y == -1], c=\"r\", marker=\"o\", edgecolors=\"k\"\n",
    "# )\n",
    "# plt.title(\"Feature vectors (dims {} and {})\".format(dim1, dim2))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a59fb6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "num_data = len(Y)\n",
    "\n",
    "# num_train = int(0.75 * num_data)\n",
    "num_train = int(0.75 * num_data)\n",
    "index = np.random.permutation(range(num_data))\n",
    "\n",
    "feats_train = features[index[:num_train]]\n",
    "Y_train = Y[index[:num_train]]\n",
    "\n",
    "feats_val = features[index[num_train:]]\n",
    "Y_val = Y[index[num_train:]]\n",
    "\n",
    "# We need these later for plotting\n",
    "X_train = X[index[:num_train]]\n",
    "X_val = X[index[num_train:]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "544af8f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:     1 | Cost: 1.1942728 | Acc train: 0.5333333 | Acc validation: 0.5066667 \n",
      "Iter:     2 | Cost: 1.1980613 | Acc train: 0.5111111 | Acc validation: 0.5333333 \n",
      "Iter:     3 | Cost: 1.2161650 | Acc train: 0.5022222 | Acc validation: 0.5200000 \n",
      "Iter:     4 | Cost: 1.2344483 | Acc train: 0.4977778 | Acc validation: 0.5333333 \n",
      "Iter:     5 | Cost: 1.2549363 | Acc train: 0.4933333 | Acc validation: 0.4933333 \n",
      "Iter:     6 | Cost: 1.2873434 | Acc train: 0.4933333 | Acc validation: 0.4933333 \n",
      "Iter:     7 | Cost: 1.3183583 | Acc train: 0.5022222 | Acc validation: 0.4933333 \n",
      "Iter:     8 | Cost: 1.3291061 | Acc train: 0.4933333 | Acc validation: 0.4800000 \n",
      "Iter:     9 | Cost: 1.3015293 | Acc train: 0.4977778 | Acc validation: 0.4933333 \n",
      "Iter:    10 | Cost: 1.2507147 | Acc train: 0.4844444 | Acc validation: 0.4933333 \n",
      "Iter:    11 | Cost: 1.1958381 | Acc train: 0.5066667 | Acc validation: 0.5333333 \n",
      "Iter:    12 | Cost: 1.1622816 | Acc train: 0.5244444 | Acc validation: 0.5333333 \n",
      "Iter:    13 | Cost: 1.1253319 | Acc train: 0.5644444 | Acc validation: 0.5733333 \n",
      "Iter:    14 | Cost: 1.0978532 | Acc train: 0.5822222 | Acc validation: 0.5600000 \n",
      "Iter:    15 | Cost: 1.0786243 | Acc train: 0.5866667 | Acc validation: 0.5466667 \n",
      "Iter:    16 | Cost: 1.0631955 | Acc train: 0.6044444 | Acc validation: 0.5866667 \n",
      "Iter:    17 | Cost: 1.0441251 | Acc train: 0.6088889 | Acc validation: 0.5733333 \n",
      "Iter:    18 | Cost: 1.0271192 | Acc train: 0.6088889 | Acc validation: 0.5733333 \n",
      "Iter:    19 | Cost: 1.0119229 | Acc train: 0.6311111 | Acc validation: 0.5600000 \n",
      "Iter:    20 | Cost: 0.9979846 | Acc train: 0.6311111 | Acc validation: 0.5600000 \n",
      "Iter:    21 | Cost: 0.9718262 | Acc train: 0.6400000 | Acc validation: 0.5733333 \n",
      "Iter:    22 | Cost: 0.9451144 | Acc train: 0.6488889 | Acc validation: 0.6000000 \n",
      "Iter:    23 | Cost: 0.9171595 | Acc train: 0.6666667 | Acc validation: 0.6133333 \n",
      "Iter:    24 | Cost: 0.8841294 | Acc train: 0.6844444 | Acc validation: 0.6266667 \n",
      "Iter:    25 | Cost: 0.8499631 | Acc train: 0.6888889 | Acc validation: 0.6800000 \n",
      "Iter:    26 | Cost: 0.8191736 | Acc train: 0.6977778 | Acc validation: 0.6800000 \n",
      "Iter:    27 | Cost: 0.7886029 | Acc train: 0.7066667 | Acc validation: 0.7066667 \n",
      "Iter:    28 | Cost: 0.7552843 | Acc train: 0.7333333 | Acc validation: 0.7333333 \n",
      "Iter:    29 | Cost: 0.7253672 | Acc train: 0.7600000 | Acc validation: 0.7466667 \n",
      "Iter:    30 | Cost: 0.7003873 | Acc train: 0.7555556 | Acc validation: 0.7333333 \n",
      "Iter:    31 | Cost: 0.6821458 | Acc train: 0.7733333 | Acc validation: 0.7333333 \n",
      "Iter:    32 | Cost: 0.6625347 | Acc train: 0.7822222 | Acc validation: 0.7466667 \n",
      "Iter:    33 | Cost: 0.6484501 | Acc train: 0.8088889 | Acc validation: 0.7733333 \n",
      "Iter:    34 | Cost: 0.6388949 | Acc train: 0.8044444 | Acc validation: 0.7866667 \n",
      "Iter:    35 | Cost: 0.6316344 | Acc train: 0.8000000 | Acc validation: 0.8133333 \n",
      "Iter:    36 | Cost: 0.6271471 | Acc train: 0.8044444 | Acc validation: 0.8266667 \n",
      "Iter:    37 | Cost: 0.6250258 | Acc train: 0.8222222 | Acc validation: 0.8266667 \n",
      "Iter:    38 | Cost: 0.6263670 | Acc train: 0.7955556 | Acc validation: 0.8533333 \n",
      "Iter:    39 | Cost: 0.6298867 | Acc train: 0.7822222 | Acc validation: 0.8266667 \n",
      "Iter:    40 | Cost: 0.6328936 | Acc train: 0.7688889 | Acc validation: 0.8133333 \n",
      "Iter:    41 | Cost: 0.6274343 | Acc train: 0.7955556 | Acc validation: 0.8266667 \n",
      "Iter:    42 | Cost: 0.6186443 | Acc train: 0.8133333 | Acc validation: 0.8266667 \n",
      "Iter:    43 | Cost: 0.6066136 | Acc train: 0.8133333 | Acc validation: 0.8266667 \n",
      "Iter:    44 | Cost: 0.5985018 | Acc train: 0.8177778 | Acc validation: 0.8266667 \n",
      "Iter:    45 | Cost: 0.5917224 | Acc train: 0.8355556 | Acc validation: 0.8266667 \n",
      "Iter:    46 | Cost: 0.5831243 | Acc train: 0.8400000 | Acc validation: 0.8266667 \n",
      "Iter:    47 | Cost: 0.5783729 | Acc train: 0.8355556 | Acc validation: 0.8400000 \n",
      "Iter:    48 | Cost: 0.5736507 | Acc train: 0.8311111 | Acc validation: 0.8266667 \n",
      "Iter:    49 | Cost: 0.5710263 | Acc train: 0.8355556 | Acc validation: 0.8266667 \n",
      "Iter:    50 | Cost: 0.5699690 | Acc train: 0.8400000 | Acc validation: 0.8400000 \n",
      "___:  [-0.99879119 -1.00087518  0.9993123   0.99949847 -1.00063008  0.99624721\n",
      "  0.99504035  0.99670086 -0.9957306  -1.00028303]\n",
      "bias:  -0.4839021194740366\n"
     ]
    }
   ],
   "source": [
    "weights_init = 0.01 * np.random.randn(num_layers, num_qubits, 3, requires_grad=True)\n",
    "bias_init = np.array(0.0, requires_grad=True)\n",
    "\n",
    "# # start with learned step\n",
    "# w = np.load('/_jupyter/QC/QOSF-challenge-md-2022/task-02/temp-data/variational_classifier/data/mock_train_numpy_wights_01.npy', allow_pickle=True)\n",
    "# weights_init = np.array(w, requires_grad=True)\n",
    "# bias_init = np.array(-0.483902119474, requires_grad=True)\n",
    "\n",
    "\n",
    "opt = NesterovMomentumOptimizer(0.01)\n",
    "# opt = NesterovMomentumOptimizer(0.1)\n",
    "# opt = NesterovMomentumOptimizer(0.1)\n",
    "batch_size = 5\n",
    "batch_size = 15\n",
    "batch_size = 20\n",
    "batch_size = 10\n",
    "\n",
    "\n",
    "# train the variational classifier\n",
    "weights = weights_init\n",
    "bias = bias_init\n",
    "# for it in range(60):\n",
    "steps = 50\n",
    "# steps = 5\n",
    "for it in range(steps):\n",
    "# for it in range(2):\n",
    "\n",
    "    # Update the weights by one optimizer step\n",
    "    batch_index = np.random.randint(0, num_train, (batch_size,))\n",
    "    feats_train_batch = feats_train[batch_index]\n",
    "    Y_train_batch = Y_train[batch_index]\n",
    "    weights, bias, _, _ = opt.step(cost, weights, bias, feats_train_batch, Y_train_batch)\n",
    "\n",
    "    # Compute predictions on train and validation set\n",
    "    predictions_train = [np.sign(variational_classifier(weights, bias, f)) for f in feats_train]\n",
    "    predictions_val = [np.sign(variational_classifier(weights, bias, f)) for f in feats_val]\n",
    "\n",
    "    # Compute accuracy on train and validation set\n",
    "    acc_train = accuracy(Y_train, predictions_train)\n",
    "    acc_val = accuracy(Y_val, predictions_val)\n",
    "\n",
    "    print(\n",
    "        \"Iter: {:5d} | Cost: {:0.7f} | Acc train: {:0.7f} | Acc validation: {:0.7f} \"\n",
    "        \"\".format(it + 1, cost(weights, bias, features, Y), acc_train, acc_val)\n",
    "    )\n",
    "    if acc_train >= 0.93 and acc_val >= 0.93:\n",
    "        # early stop\n",
    "        break\n",
    "\n",
    "print('___: ', _)    \n",
    "print('bias: ', bias)    \n",
    "# print('weights:\\n', weights)\n",
    "# np.save('/_jupyter/QC/QOSF-challenge-md-2022/task-02/temp-data/variational_classifier/data/mock_train_numpy_wights_02.npy', weights, allow_pickle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f55127",
   "metadata": {},
   "source": [
    "Load the test dataset and apply same transformations as we did with the train dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b98d9a9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(with_mean=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data: 0.9583\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the test dataset and apply same transformations as we did with the train dataset.\n",
    "df = pd.read_csv(path_test)\n",
    "df_c = df.copy(deep=True)\n",
    "df['1'] = np.log10(df_c['1'])\n",
    "df['2'] = np.log10(df_c['2'])\n",
    "\n",
    "f = lambda x: -1.0 if x==0 else 1.0\n",
    "df['4'] = df_c['4'].map(f)\n",
    "npdf = df.to_numpy()\n",
    "data = np.array(npdf)\n",
    "\n",
    "X = data[:, 0:4]\n",
    "Y_test = data[:, -1]\n",
    "\n",
    "# scale data using sklearn StandardScaler\n",
    "std_slc = StandardScaler(with_mean=False)\n",
    "std_slc.fit(X)\n",
    "X_std = std_slc.transform(X)\n",
    "\n",
    "# normalize data using sklearn StandardScaler\n",
    "normalizer = Normalizer().fit(X_std)  # fit does nothing.\n",
    "X_norm = normalizer.transform(X_std)\n",
    "\n",
    "# convert to a pennylane numpy array\n",
    "X_test = np.array(X_norm, requires_grad=False)\n",
    "\n",
    "# apply the variational clasifier circuit on test dataset\n",
    "# using the learned weights\n",
    "predictions_test = [np.sign(variational_classifier(weights, bias, f)) for f in X_test]\n",
    "\n",
    "acc_test = accuracy(Y_test, predictions_test)\n",
    "print('Accuracy on test data: {:0.4f}'.format(acc_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5fad434",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_85727/699758149.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# We can plot the continuous output of the variational classifier for the first two dimensions of the Iris data set.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRdBu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# make data for decision regions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# We can plot the continuous output of the variational classifier for the first two dimensions of the Iris data set.\n",
    "plt.figure()\n",
    "cm = plt.cm.RdBu\n",
    "\n",
    "# make data for decision regions\n",
    "xx, yy = np.meshgrid(np.linspace(0.0, 1.5, 300), np.linspace(0.0, 1.5, 300))\n",
    "X_grid = [np.array([x, y]) for x, y in zip(xx.flatten(), yy.flatten())]\n",
    "\n",
    "pd.DataFrame(xx).shape\n",
    "pd.DataFrame(yy).shape\n",
    "pd.DataFrame(X_grid).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47506f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # # preprocess grid points like data inputs above\n",
    "# # padding = 0.3 * np.ones((len(X_grid), 1))\n",
    "# # X_grid = np.c_[np.c_[X_grid, padding], np.zeros((len(X_grid), 1))]  # pad each input\n",
    "\n",
    "# # normalization = np.sqrt(np.sum(X_grid ** 2, -1))\n",
    "# # X_grid = (X_grid.T / normalization).T  # normalize each input\n",
    "\n",
    "# # features_grid = np.array(\n",
    "# #     [get_angles(x) for x in X_grid]\n",
    "# # )  # angles for state preparation are new features\n",
    "\n",
    "# X_grid = X_norm\n",
    "# features_grid = X_grid\n",
    "# predictions_grid = [variational_classifier(weights, bias, f) for f in features_grid]\n",
    "# # Z = np.reshape(predictions_grid, xx.shape)\n",
    "# Z = predictions_grid \n",
    "\n",
    "# # plot decision regions\n",
    "# cnt = plt.contourf(\n",
    "#     xx, yy, Z, levels=np.arange(-1, 1.1, 0.1), cmap=cm, alpha=0.8, extend=\"both\"\n",
    "# )\n",
    "# plt.contour(\n",
    "#     xx, yy, Z, levels=[0.0], colors=(\"black\",), linestyles=(\"--\",), linewidths=(0.8,)\n",
    "# )\n",
    "# plt.colorbar(cnt, ticks=[-1, 0, 1])\n",
    "\n",
    "# # plot data\n",
    "# plt.scatter(\n",
    "#     X_train[:, 0][Y_train == 1],\n",
    "#     X_train[:, 1][Y_train == 1],\n",
    "#     c=\"b\",\n",
    "#     marker=\"o\",\n",
    "#     edgecolors=\"k\",\n",
    "#     label=\"class 1 train\",\n",
    "# )\n",
    "# plt.scatter(\n",
    "#     X_val[:, 0][Y_val == 1],\n",
    "#     X_val[:, 1][Y_val == 1],\n",
    "#     c=\"b\",\n",
    "#     marker=\"^\",\n",
    "#     edgecolors=\"k\",\n",
    "#     label=\"class 1 validation\",\n",
    "# )\n",
    "# # plt.scatter(\n",
    "# #     X_train[:, 0][Y_train == -1],\n",
    "# #     X_train[:, 1][Y_train == -1],\n",
    "# #     c=\"r\",\n",
    "# #     marker=\"o\",\n",
    "# #     edgecolors=\"k\",\n",
    "# #     label=\"class -1 train\",\n",
    "# # )\n",
    "# # plt.scatter(\n",
    "# #     X_val[:, 0][Y_val == -1],\n",
    "# #     X_val[:, 1][Y_val == -1],\n",
    "# #     c=\"r\",\n",
    "# #     marker=\"^\",\n",
    "# #     edgecolors=\"k\",\n",
    "# #     label=\"class -1 validation\",\n",
    "# # )\n",
    "\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17a310c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
