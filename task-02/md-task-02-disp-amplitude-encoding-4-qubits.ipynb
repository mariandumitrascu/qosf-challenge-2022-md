{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ccfe335-e640-4b2c-b933-cba2bd38fab7",
   "metadata": {},
   "source": [
    "# Task 2 Encoding and Classifier\n",
    "\n",
    "## Problem \n",
    "<br>\n",
    "Encoding the following files in a quantum circuit mock_train_set.csv and mock_test_set.csv in at least two different ways (these could be basis, angle, amplitude, kernel or random encoding\n",
    "<br>\n",
    "<br>\n",
    "● Design a variational quantum circuit for each of the encodings, uses the column 4 as the target, this is a binary class 0 and 1.<br>\n",
    "● You must use the data from column0 to column3 for your proposed classifier.<br>\n",
    "● Consider the ansatz you are going to design as a layer and find out how many layers are\n",
    "necessary to reach the best performance. <br>\n",
    "\n",
    "### Analyze and discuss the results\n",
    "\n",
    "Feel free to use existing frameworks (e.g. PennyLane, Qiskit) for creating and training the circuits.<br><br>\n",
    "This PennyLane demo can be useful: Training a quantum circuit with Pytorch,<br>\n",
    "This Quantum Tensorflow tutorial can be useful: Training a quantum circuit with Tensorflow.<br>\n",
    "For the variational circuit, you can try any circuit you want. You can start from one with a layer of RX, RZ and CNOTs.<br>\n",
    "<br>\n",
    "## References\n",
    "* https://pennylane.ai/qml/demos/tutorial_state_preparation.html\n",
    "* https://www.tensorflow.org/quantum/tutorials/mnist\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7528820f",
   "metadata": {},
   "source": [
    "## Clasification Using Amplitude Encoding on 2 Qubits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d2481de7-3eb0-4d54-ae30-a6b8b55637bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f3fb9ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "from pennylane.optimize import NesterovMomentumOptimizer\n",
    "\n",
    "import sys\n",
    "from math import sqrt, pi\n",
    "\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "# supress a warning that is not useful here\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "407ceefd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data standardised:\n",
      " [[ 2.78926e+03  3.00000e+00  1.00000e+00  2.00000e+01 -1.00000e+00]\n",
      " [ 4.04001e+03  6.00000e+00  0.00000e+00  1.00000e+00  1.00000e+00]\n",
      " [ 2.93120e+03  4.00000e+00  4.00000e+00  4.00000e+01  1.00000e+00]\n",
      " ...\n",
      " [ 4.18281e+03  0.00000e+00  0.00000e+00  6.50000e+01 -1.00000e+00]\n",
      " [ 3.11375e+03  4.00000e+00  2.00000e+00  1.00000e+00  1.00000e+00]\n",
      " [ 4.56757e+03  4.00000e+00  5.00000e+00  9.00000e+01  1.00000e+00]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data normalized:\n",
      " [[ 0.08683356 -0.03797654 -0.66528081 -0.74055328]\n",
      " [ 0.37612267  0.45694046 -0.51293519 -0.62179952]\n",
      " [ 0.26356815  0.46027486  0.79974818 -0.28121474]\n",
      " ...\n",
      " [ 0.47981546 -0.57210908 -0.59413647  0.29911565]\n",
      " [ 0.1940783   0.21079313 -0.20305745 -0.93630526]\n",
      " [ 0.56534373  0.1530959   0.47275529  0.65836961]]\n"
     ]
    }
   ],
   "source": [
    "# sklearn StandardScaler\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html\n",
    "\n",
    "path_train = '/_jupyter/QC/QOSF-challenge-md-2022/task-02/mock_train_set.csv'\n",
    "path_test = '/_jupyter/QC/QOSF-challenge-md-2022/task-02/mock_test_set.csv'\n",
    "\n",
    "df = pd.read_csv(path_train)\n",
    "df_c = df.copy(deep=True)\n",
    "df['1'] = np.log10(df_c['1'])\n",
    "df['2'] = np.log10(df_c['2'])\n",
    "\n",
    "f = lambda x: -1.0 if x==0 else 1.0\n",
    "df['4'] = df_c['4'].map(f)\n",
    "\n",
    "# npdf = df2.to_numpy()\n",
    "npdf = df.to_numpy()\n",
    "data = np.array(npdf)\n",
    "\n",
    "print(\"Train data standardised:\\n\", data)\n",
    "\n",
    "X = data[:, 0:4]\n",
    "Y = data[:, -1]\n",
    "\n",
    "# scale the data using sklearn StandardScaler\n",
    "# std_slc = StandardScaler(with_mean=False)\n",
    "std_slc = StandardScaler(with_mean=True)\n",
    "std_slc.fit(X)\n",
    "X_std = std_slc.transform(X)\n",
    "\n",
    "# normalize data using sklearn StandardScaler\n",
    "normalizer = Normalizer().fit(X_std)  # fit does nothing.\n",
    "X_norm = normalizer.transform(X_std)\n",
    "\n",
    "# features will be the angles vector\n",
    "features = np.array(X_norm, requires_grad=False)\n",
    "print(\"Train data normalized:\\n\", features)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6b43a2",
   "metadata": {},
   "source": [
    "Circuit coding for angle encoding follows pennylane technique, whch is also following the scheme in in Schuld and Petruccione (2018).<br>\n",
    "\"\"We had to also decompose controlled Y-axis rotations into more basic circuits following Nielsen and Chuang (2010).\"\"<br>\n",
    "\n",
    "* https://link.springer.com/book/10.1007/978-3-319-96424-9\n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a9388875",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_qubits = 4\n",
    "# num_layers = 2\n",
    "num_layers = 8\n",
    "\n",
    "dev = qml.device(\"default.gaussian\", wires=num_qubits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200e536c",
   "metadata": {},
   "source": [
    "### test angle encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c55af916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainable circuit layer\n",
    "def layer(W):\n",
    "    for i in range(num_qubits):\n",
    "\n",
    "        mag_alpha =  W[i, 0]\n",
    "        phase_alpha = W[i, 1]\n",
    "        phi = W[i, 2]\n",
    "\n",
    "        qml.Displacement(mag_alpha, phase_alpha, wires=i)\n",
    "        qml.Rotation(phi, wires=i)\n",
    "\n",
    "# circuit that gets evaluated and optimised on each step\n",
    "@qml.qnode(dev)\n",
    "def circuit(weights, data):\n",
    "\n",
    "    qml.DisplacementEmbedding(features=data, wires=range(num_qubits), method='amplitude')\n",
    "\n",
    "    # apply trainable layers\n",
    "    for W in weights:\n",
    "        layer(W)\n",
    "\n",
    "    return qml.expval(qml.NumberOperator(wires=1))\n",
    "\n",
    "draw_flag = 0\n",
    "def variational_classifier(weights, bias, data):\n",
    "    \n",
    "    global draw_flag\n",
    "\n",
    "    if draw_flag:\n",
    "        draw_flag=0\n",
    "        # qml.draw\n",
    "\n",
    "    return circuit(weights, data) + bias\n",
    "\n",
    "# ###############################################################################\n",
    "# standard square loss\n",
    "def square_loss(labels, predictions):\n",
    "    \n",
    "    loss = 0\n",
    "    for l, p in zip(labels, predictions):\n",
    "        loss = loss + (l - p) ** 2\n",
    "\n",
    "    loss = loss / len(labels)\n",
    "    return loss\n",
    "\n",
    "# ###############################################################################\n",
    "# goal: maximize accuracy\n",
    "def accuracy(labels, predictions):\n",
    "\n",
    "    loss = 0\n",
    "    for l, p in zip(labels, predictions):\n",
    "        if abs(l - p) < 1e-5:\n",
    "            loss = loss + 1\n",
    "    loss = loss / len(labels)\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "def cost(weights, bias, features, labels):\n",
    "    \n",
    "    predictions = [variational_classifier(weights, bias, f) for f in features]\n",
    "    return square_loss(labels, predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a59fb6d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(with_mean=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "num_data = len(Y)\n",
    "\n",
    "# num_train = int(0.75 * num_data)\n",
    "num_train = int(0.75 * num_data)\n",
    "index = np.random.permutation(range(num_data))\n",
    "\n",
    "feats_train = features[index[:num_train]]\n",
    "Y_train = Y[index[:num_train]]\n",
    "\n",
    "feats_val = features[index[num_train:]]\n",
    "Y_val = Y[index[num_train:]]\n",
    "\n",
    "# We need these later for plotting\n",
    "X_train = X[index[:num_train]]\n",
    "X_val = X[index[num_train:]]\n",
    "\n",
    "# ######################################################################\n",
    "# Load the test dataset and apply same transformations as we did with the train dataset.\n",
    "df_test = pd.read_csv(path_test)\n",
    "df_test_c = df_test.copy(deep=True)\n",
    "df_test['1'] = np.log10(df_test_c['1'])\n",
    "df_test['2'] = np.log10(df_test_c['2'])\n",
    "\n",
    "f = lambda x: -1.0 if x==0 else 1.0\n",
    "df_test['4'] = df_test_c['4'].map(f)\n",
    "data_test = df_test.to_numpy()\n",
    "\n",
    "X_test_ini = data_test[:, 0:4]\n",
    "Y_test = data_test[:, -1]\n",
    "\n",
    "# scale data using sklearn StandardScaler\n",
    "std_slc = StandardScaler(with_mean=False)\n",
    "std_slc.fit(X_test_ini)\n",
    "X_test_std = std_slc.transform(X_test_ini)\n",
    "\n",
    "# normalize data using sklearn StandardScaler\n",
    "normalizer = Normalizer().fit(X_test_std)  # fit does nothing.\n",
    "X_test_norm = normalizer.transform(X_test_std)\n",
    "\n",
    "# convert to a pennylane numpy array\n",
    "X_test = np.array(X_test_norm, requires_grad=False)\n",
    "\n",
    "\n",
    "# ######################################################################\n",
    "# accuracy for test dtaset\n",
    "def test_accuracy(weights, bias):\n",
    "    # apply the variational clasifier circuit on test dataset\n",
    "    # using the learned weights\n",
    "    predictions_test = [np.sign(variational_classifier(weights, bias, f)) for f in X_test]\n",
    "\n",
    "    return accuracy(Y_test, predictions_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "544af8f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:     1 | Cost: 0.9744105 | Acc train: 0.5200000 | Acc validation: 0.4666667 | Acc test: 0.5166667 \n",
      "Iter:     2 | Cost: 0.9158187 | Acc train: 0.6711111 | Acc validation: 0.6400000 | Acc test: 0.5166667 \n",
      "Iter:     3 | Cost: 1.1297534 | Acc train: 0.7555556 | Acc validation: 0.7333333 | Acc test: 0.5166667 \n",
      "Iter:     4 | Cost: 0.8531698 | Acc train: 0.7600000 | Acc validation: 0.7200000 | Acc test: 0.5166667 \n",
      "Iter:     5 | Cost: 0.8985145 | Acc train: 0.6711111 | Acc validation: 0.7200000 | Acc test: 0.8583333 \n",
      "Iter:     6 | Cost: 0.9580070 | Acc train: 0.5022222 | Acc validation: 0.6133333 | Acc test: 0.9166667 \n",
      "Iter:     7 | Cost: 0.9119485 | Acc train: 0.6088889 | Acc validation: 0.6533333 | Acc test: 0.9166667 \n",
      "Iter:     8 | Cost: 0.7929147 | Acc train: 0.7555556 | Acc validation: 0.8266667 | Acc test: 0.8833333 \n",
      "Iter:     9 | Cost: 0.7388000 | Acc train: 0.8622222 | Acc validation: 0.8800000 | Acc test: 0.8166667 \n",
      "Iter:    10 | Cost: 0.7742567 | Acc train: 0.8133333 | Acc validation: 0.8000000 | Acc test: 0.5166667 \n",
      "Iter:    11 | Cost: 0.7459778 | Acc train: 0.8622222 | Acc validation: 0.8800000 | Acc test: 0.5166667 \n",
      "Iter:    12 | Cost: 0.7048565 | Acc train: 0.8622222 | Acc validation: 0.8800000 | Acc test: 0.8166667 \n",
      "Iter:    13 | Cost: 0.6774918 | Acc train: 0.8577778 | Acc validation: 0.8800000 | Acc test: 0.8583333 \n",
      "Iter:    14 | Cost: 0.6678394 | Acc train: 0.8488889 | Acc validation: 0.8800000 | Acc test: 0.8583333 \n",
      "Iter:    15 | Cost: 0.6792443 | Acc train: 0.8622222 | Acc validation: 0.8800000 | Acc test: 0.8166667 \n",
      "Iter:    16 | Cost: 0.7487194 | Acc train: 0.8622222 | Acc validation: 0.8800000 | Acc test: 0.5166667 \n",
      "Iter:    17 | Cost: 0.6891928 | Acc train: 0.7022222 | Acc validation: 0.8000000 | Acc test: 0.9250000 \n",
      "Iter:    18 | Cost: 0.7753989 | Acc train: 0.6844444 | Acc validation: 0.7733333 | Acc test: 0.8583333 \n",
      "Iter:    19 | Cost: 0.7995379 | Acc train: 0.6755556 | Acc validation: 0.7333333 | Acc test: 0.8166667 \n",
      "Iter:    20 | Cost: 0.6842881 | Acc train: 0.6977778 | Acc validation: 0.7866667 | Acc test: 0.9416667 \n",
      "Iter:    21 | Cost: 0.6773676 | Acc train: 0.6977778 | Acc validation: 0.8000000 | Acc test: 0.9250000 \n",
      "Iter:    22 | Cost: 0.6398095 | Acc train: 0.8311111 | Acc validation: 0.8666667 | Acc test: 0.8666667 \n",
      "Iter:    23 | Cost: 0.6811715 | Acc train: 0.6977778 | Acc validation: 0.7866667 | Acc test: 0.9416667 \n",
      "Iter:    24 | Cost: 0.7114827 | Acc train: 0.6933333 | Acc validation: 0.7866667 | Acc test: 0.9000000 \n",
      "Iter:    25 | Cost: 0.6786504 | Acc train: 0.6977778 | Acc validation: 0.7866667 | Acc test: 0.9416667 \n",
      "Iter:    26 | Cost: 0.6457463 | Acc train: 0.7066667 | Acc validation: 0.8266667 | Acc test: 0.9000000 \n",
      "Iter:    27 | Cost: 0.6574342 | Acc train: 0.8622222 | Acc validation: 0.8800000 | Acc test: 0.8333333 \n",
      "Iter:    28 | Cost: 0.6527715 | Acc train: 0.8622222 | Acc validation: 0.8800000 | Acc test: 0.8500000 \n",
      "Iter:    29 | Cost: 0.6451448 | Acc train: 0.7066667 | Acc validation: 0.8266667 | Acc test: 0.9000000 \n",
      "Iter:    30 | Cost: 0.8058100 | Acc train: 0.6666667 | Acc validation: 0.7333333 | Acc test: 0.7833333 \n",
      "Iter:    31 | Cost: 0.9467015 | Acc train: 0.5866667 | Acc validation: 0.6266667 | Acc test: 0.5916667 \n",
      "Iter:    32 | Cost: 0.9812236 | Acc train: 0.5688889 | Acc validation: 0.6400000 | Acc test: 0.5333333 \n",
      "Iter:    33 | Cost: 0.8594923 | Acc train: 0.6444444 | Acc validation: 0.6800000 | Acc test: 0.7083333 \n",
      "Iter:    34 | Cost: 0.7462129 | Acc train: 0.6844444 | Acc validation: 0.7866667 | Acc test: 0.8666667 \n",
      "Iter:    35 | Cost: 0.6564631 | Acc train: 0.7066667 | Acc validation: 0.8133333 | Acc test: 0.9250000 \n",
      "Iter:    36 | Cost: 0.6478502 | Acc train: 0.8622222 | Acc validation: 0.8800000 | Acc test: 0.8500000 \n",
      "Iter:    37 | Cost: 0.7066550 | Acc train: 0.8622222 | Acc validation: 0.8800000 | Acc test: 0.8166667 \n",
      "Iter:    38 | Cost: 0.6593115 | Acc train: 0.7066667 | Acc validation: 0.8133333 | Acc test: 0.9250000 \n",
      "Iter:    39 | Cost: 0.6698612 | Acc train: 0.7022222 | Acc validation: 0.8000000 | Acc test: 0.9166667 \n",
      "Iter:    40 | Cost: 0.6423062 | Acc train: 0.7555556 | Acc validation: 0.8533333 | Acc test: 0.8833333 \n",
      "Iter:    41 | Cost: 0.6711208 | Acc train: 0.8622222 | Acc validation: 0.8800000 | Acc test: 0.8166667 \n",
      "Iter:    42 | Cost: 0.6912354 | Acc train: 0.8622222 | Acc validation: 0.8800000 | Acc test: 0.8166667 \n",
      "Iter:    43 | Cost: 0.6431642 | Acc train: 0.8311111 | Acc validation: 0.8800000 | Acc test: 0.8666667 \n",
      "Iter:    44 | Cost: 0.6479850 | Acc train: 0.7200000 | Acc validation: 0.8400000 | Acc test: 0.9083333 \n",
      "Iter:    45 | Cost: 0.6465136 | Acc train: 0.7244444 | Acc validation: 0.8400000 | Acc test: 0.9083333 \n",
      "Iter:    46 | Cost: 0.6513006 | Acc train: 0.7111111 | Acc validation: 0.8266667 | Acc test: 0.9000000 \n",
      "Iter:    47 | Cost: 0.6863892 | Acc train: 0.7022222 | Acc validation: 0.7866667 | Acc test: 0.9416667 \n",
      "Iter:    48 | Cost: 0.6730517 | Acc train: 0.7022222 | Acc validation: 0.8000000 | Acc test: 0.9250000 \n",
      "Iter:    49 | Cost: 0.6515709 | Acc train: 0.7066667 | Acc validation: 0.8266667 | Acc test: 0.9000000 \n",
      "Iter:    50 | Cost: 0.6464761 | Acc train: 0.8622222 | Acc validation: 0.8800000 | Acc test: 0.8583333 \n",
      "Iter:    51 | Cost: 0.6370430 | Acc train: 0.7644444 | Acc validation: 0.8533333 | Acc test: 0.8833333 \n",
      "Iter:    52 | Cost: 0.6424983 | Acc train: 0.7200000 | Acc validation: 0.8400000 | Acc test: 0.9083333 \n",
      "Iter:    53 | Cost: 0.6560757 | Acc train: 0.8622222 | Acc validation: 0.8800000 | Acc test: 0.8333333 \n",
      "Iter:    54 | Cost: 0.6965939 | Acc train: 0.8622222 | Acc validation: 0.8800000 | Acc test: 0.8166667 \n",
      "Iter:    55 | Cost: 0.6984119 | Acc train: 0.8622222 | Acc validation: 0.8800000 | Acc test: 0.8166667 \n",
      "Iter:    56 | Cost: 0.6723213 | Acc train: 0.8622222 | Acc validation: 0.8800000 | Acc test: 0.8166667 \n",
      "Iter:    57 | Cost: 0.7108670 | Acc train: 0.6933333 | Acc validation: 0.7866667 | Acc test: 0.9000000 \n",
      "Iter:    58 | Cost: 0.8585803 | Acc train: 0.6444444 | Acc validation: 0.6800000 | Acc test: 0.7166667 \n",
      "Iter:    59 | Cost: 0.8937394 | Acc train: 0.6133333 | Acc validation: 0.6666667 | Acc test: 0.6500000 \n",
      "Iter:    60 | Cost: 0.7609040 | Acc train: 0.6844444 | Acc validation: 0.7733333 | Acc test: 0.8583333 \n",
      "Iter:    61 | Cost: 0.6564706 | Acc train: 0.7066667 | Acc validation: 0.8133333 | Acc test: 0.9250000 \n",
      "Iter:    62 | Cost: 0.6503801 | Acc train: 0.8622222 | Acc validation: 0.8800000 | Acc test: 0.8500000 \n",
      "Iter:    63 | Cost: 0.6729499 | Acc train: 0.8622222 | Acc validation: 0.8800000 | Acc test: 0.8166667 \n",
      "Iter:    64 | Cost: 0.6876270 | Acc train: 0.8622222 | Acc validation: 0.8800000 | Acc test: 0.8166667 \n",
      "Iter:    65 | Cost: 0.6602481 | Acc train: 0.7066667 | Acc validation: 0.8133333 | Acc test: 0.9250000 \n",
      "Iter:    66 | Cost: 0.7120187 | Acc train: 0.6933333 | Acc validation: 0.7866667 | Acc test: 0.9083333 \n",
      "Iter:    67 | Cost: 0.7203190 | Acc train: 0.6933333 | Acc validation: 0.7866667 | Acc test: 0.9000000 \n",
      "Iter:    68 | Cost: 0.6645235 | Acc train: 0.7066667 | Acc validation: 0.8133333 | Acc test: 0.9250000 \n",
      "Iter:    69 | Cost: 0.6415106 | Acc train: 0.7866667 | Acc validation: 0.8533333 | Acc test: 0.8750000 \n",
      "Iter:    70 | Cost: 0.6545859 | Acc train: 0.8622222 | Acc validation: 0.8800000 | Acc test: 0.8500000 \n",
      "Iter:    71 | Cost: 0.6652872 | Acc train: 0.8622222 | Acc validation: 0.8800000 | Acc test: 0.8333333 \n",
      "Iter:    72 | Cost: 0.8603365 | Acc train: 0.6622222 | Acc validation: 0.6800000 | Acc test: 0.7166667 \n",
      "Iter:    73 | Cost: 1.1067461 | Acc train: 0.5200000 | Acc validation: 0.6000000 | Acc test: 0.4916667 \n",
      "Iter:    74 | Cost: 1.2214411 | Acc train: 0.4977778 | Acc validation: 0.5466667 | Acc test: 0.4833333 \n",
      "Iter:    75 | Cost: 1.1631399 | Acc train: 0.5111111 | Acc validation: 0.5733333 | Acc test: 0.4833333 \n",
      "Iter:    76 | Cost: 1.0109337 | Acc train: 0.5600000 | Acc validation: 0.6133333 | Acc test: 0.5166667 \n",
      "Iter:    77 | Cost: 0.7636423 | Acc train: 0.6844444 | Acc validation: 0.7733333 | Acc test: 0.8583333 \n",
      "Iter:    78 | Cost: 0.6612051 | Acc train: 0.8622222 | Acc validation: 0.8800000 | Acc test: 0.8333333 \n",
      "Iter:    79 | Cost: 0.7714071 | Acc train: 0.8622222 | Acc validation: 0.8800000 | Acc test: 0.5166667 \n",
      "Iter:    80 | Cost: 0.7154465 | Acc train: 0.8622222 | Acc validation: 0.8800000 | Acc test: 0.8166667 \n",
      "Iter:    81 | Cost: 0.6577634 | Acc train: 0.7066667 | Acc validation: 0.8266667 | Acc test: 0.9166667 \n",
      "Iter:    82 | Cost: 0.7010022 | Acc train: 0.6977778 | Acc validation: 0.7866667 | Acc test: 0.9333333 \n",
      "Iter:    83 | Cost: 0.6730369 | Acc train: 0.7022222 | Acc validation: 0.8000000 | Acc test: 0.9166667 \n",
      "Iter:    84 | Cost: 0.6504456 | Acc train: 0.8622222 | Acc validation: 0.8800000 | Acc test: 0.8500000 \n",
      "Iter:    85 | Cost: 0.6795171 | Acc train: 0.8622222 | Acc validation: 0.8800000 | Acc test: 0.8166667 \n",
      "Iter:    86 | Cost: 0.7065534 | Acc train: 0.8622222 | Acc validation: 0.8800000 | Acc test: 0.8166667 \n",
      "Iter:    87 | Cost: 0.6753567 | Acc train: 0.8622222 | Acc validation: 0.8800000 | Acc test: 0.8166667 \n",
      "Iter:    88 | Cost: 0.6408522 | Acc train: 0.8266667 | Acc validation: 0.8666667 | Acc test: 0.8666667 \n",
      "Iter:    89 | Cost: 0.6395991 | Acc train: 0.8133333 | Acc validation: 0.8666667 | Acc test: 0.8666667 \n",
      "Iter:    90 | Cost: 0.6408395 | Acc train: 0.8311111 | Acc validation: 0.8666667 | Acc test: 0.8666667 \n",
      "Iter:    91 | Cost: 0.7178314 | Acc train: 0.6933333 | Acc validation: 0.7866667 | Acc test: 0.9000000 \n",
      "Iter:    92 | Cost: 0.9525734 | Acc train: 0.5866667 | Acc validation: 0.6266667 | Acc test: 0.5916667 \n",
      "Iter:    93 | Cost: 1.1281183 | Acc train: 0.5244444 | Acc validation: 0.5866667 | Acc test: 0.4833333 \n",
      "Iter:    94 | Cost: 1.1270873 | Acc train: 0.5244444 | Acc validation: 0.5866667 | Acc test: 0.4833333 \n",
      "Iter:    95 | Cost: 0.8986977 | Acc train: 0.6133333 | Acc validation: 0.6666667 | Acc test: 0.6500000 \n"
     ]
    }
   ],
   "source": [
    "weights_init = 0.01 * np.random.randn(num_layers, num_qubits, 3, requires_grad=True)\n",
    "bias_init = np.array(0.0, requires_grad=True)\n",
    "\n",
    "# initialise the optimizer\n",
    "# opt = qml.GradientDescentOptimizer(stepsize=0.05)\n",
    "opt = NesterovMomentumOptimizer(0.01)\n",
    "# opt = NesterovMomentumOptimizer(0.008)\n",
    "# opt = NesterovMomentumOptimizer(0.1)\n",
    "# opt = NesterovMomentumOptimizer(0.1)\n",
    "# batch_size = 5\n",
    "# batch_size = 15\n",
    "# batch_size = 20\n",
    "batch_size = 10\n",
    "\n",
    "\n",
    "# train the variational classifier\n",
    "weights = weights_init\n",
    "bias = bias_init\n",
    "\n",
    "# steps = 50 # acc: 0.94\n",
    "# steps = 149  # acc: 0.92\n",
    "# steps = 150  # acc: 0.92\n",
    "# steps = 42  # acc: 0.85\n",
    "\n",
    "# phase\n",
    "steps = 95 # acc:\n",
    "# steps = 72 # acc:0.90\n",
    "\n",
    "\n",
    "for it in range(steps):\n",
    "\n",
    "    # Update the weights by one optimizer step\n",
    "    batch_index = np.random.randint(0, num_train, (batch_size,))\n",
    "    feats_train_batch = feats_train[batch_index]\n",
    "    Y_train_batch = Y_train[batch_index]\n",
    "    weights, bias, _, _ = opt.step(cost, weights, bias, feats_train_batch, Y_train_batch)\n",
    "\n",
    "    # Compute predictions on train and validation set\n",
    "    predictions_train = [np.sign(variational_classifier(weights, bias, f)) for f in feats_train]\n",
    "    predictions_val = [np.sign(variational_classifier(weights, bias, f)) for f in feats_val]\n",
    "\n",
    "    # Compute accuracy on train and validation set\n",
    "    acc_train = accuracy(Y_train, predictions_train)\n",
    "    acc_val = accuracy(Y_val, predictions_val)\n",
    "\n",
    "    acc_test = test_accuracy(weights, bias)\n",
    "\n",
    "    # print(\n",
    "    #     \"Iter: {:5d} | Cost: {:0.7f} | Acc train: {:0.7f} | Acc validation: {:0.7f} \"\n",
    "    #     \"\".format(it + 1, cost(weights, bias, features, Y), acc_train, acc_val)\n",
    "    # )\n",
    "\n",
    "    print(\n",
    "        \"Iter: {:5d} | Cost: {:0.7f} | Acc train: {:0.7f} | Acc validation: {:0.7f} | Acc test: {:0.7f} \"\n",
    "        \"\".format(it + 1, cost(weights, bias, features, Y), acc_train, acc_val, acc_test)\n",
    "    )\n",
    "    # if acc_train >= 0.88 and acc_val >= 0.88:\n",
    "    if acc_train >= 0.95 and acc_val >= 0.95 and acc_test >= 0.95:\n",
    "        # early stop\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f55127",
   "metadata": {},
   "source": [
    "Load the test dataset and apply same transformations as we did with the train dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d64dff25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:    95 | Cost: 0.8986977 | Acc train: 0.6133333 | Acc validation: 0.6666667 | Acc test: 0.6500000 \n",
      "step:  94\n",
      "bias:  -0.6488172701721436\n",
      "weights:\n",
      " [[[ 0.01126636 -0.01079932 -0.01147469]\n",
      "  [ 0.02811479 -0.01214872  0.011485  ]\n",
      "  [ 0.00949421  0.00087551 -0.01225436]\n",
      "  [ 0.00844363 -0.01000215 -0.01544771]]\n",
      "\n",
      " [[ 0.0118803   0.00316943  0.00920859]\n",
      "  [ 0.03475365  0.00355411 -0.01933477]\n",
      "  [-0.01034243  0.00681595 -0.0080341 ]\n",
      "  [-0.0068955  -0.00455533  0.00017479]]\n",
      "\n",
      " [[-0.00353994 -0.01374951 -0.00643618]\n",
      "  [ 0.01047418 -0.00237985 -0.03747726]\n",
      "  [-0.01104383  0.00052165 -0.00739563]\n",
      "  [ 0.01543015 -0.01292857  0.00267051]]\n",
      "\n",
      " [[-0.00039283 -0.01168093  0.00523277]\n",
      "  [ 0.03785403  0.01563076 -0.00530879]\n",
      "  [ 0.02163236  0.01336528 -0.00369182]\n",
      "  [-0.00239379  0.0109966   0.00655264]]\n",
      "\n",
      " [[ 0.00640132 -0.01616956 -0.00024326]\n",
      "  [ 0.02896284  0.00546121 -0.01186338]\n",
      "  [ 0.00910179  0.00317218  0.00786328]\n",
      "  [-0.00466419 -0.00944446 -0.0041005 ]]\n",
      "\n",
      " [[-0.0001702   0.00379152  0.02259309]\n",
      "  [ 0.03332803 -0.00798574 -0.01276798]\n",
      "  [-0.00463596  0.00481481 -0.01540797]\n",
      "  [ 0.00063262  0.00156507  0.00232181]]\n",
      "\n",
      " [[-0.00597316 -0.00237922 -0.01424061]\n",
      "  [ 0.03137496 -0.00100203 -0.00072108]\n",
      "  [-0.01156182  0.00781198  0.01494485]\n",
      "  [-0.02069985  0.00426259  0.00676908]]\n",
      "\n",
      " [[-0.00637437 -0.00397272 -0.00132881]\n",
      "  [ 0.03309952  0.00179145 -0.01676004]\n",
      "  [ 0.01152332  0.01079619 -0.00813364]\n",
      "  [-0.01466424  0.00521065 -0.00575788]]]\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Iter: {:5d} | Cost: {:0.7f} | Acc train: {:0.7f} | Acc validation: {:0.7f} | Acc test: {:0.7f} \"\n",
    "    \"\".format(it + 1, cost(weights, bias, features, Y), acc_train, acc_val, acc_test)\n",
    ")\n",
    "\n",
    "\n",
    "print('step: ', it)\n",
    "print('bias: ', bias)    \n",
    "print('weights:\\n', weights)\n",
    "np.save('/_jupyter/QC/QOSF-challenge-md-2022/z-temp/z-displacement-amplitude-b-001.npy', bias, allow_pickle=True)\n",
    "np.save('/_jupyter/QC/QOSF-challenge-md-2022/z-temp/z-displacement-amplitude-w-001.npy', weights, allow_pickle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b98d9a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data: 0.6500\n"
     ]
    }
   ],
   "source": [
    "\n",
    "acc_test = test_accuracy(weights, bias)\n",
    "print('Accuracy on test data: {:0.4f}'.format(acc_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d5fad434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # We can plot the continuous output of the variational classifier for the first two dimensions of the data set.\n",
    "# plt.figure()\n",
    "# cm = plt.cm.RdBu\n",
    "\n",
    "# # make data for decision regions\n",
    "# xx, yy = np.meshgrid(np.linspace(0.0, 1.5, 300), np.linspace(0.0, 1.5, 300))\n",
    "# X_grid = [np.array([x, y]) for x, y in zip(xx.flatten(), yy.flatten())]\n",
    "\n",
    "# pd.DataFrame(xx).shape\n",
    "# pd.DataFrame(yy).shape\n",
    "# pd.DataFrame(X_grid).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "47506f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # # preprocess grid points like data inputs above\n",
    "# # padding = 0.3 * np.ones((len(X_grid), 1))\n",
    "# # X_grid = np.c_[np.c_[X_grid, padding], np.zeros((len(X_grid), 1))]  # pad each input\n",
    "\n",
    "# # normalization = np.sqrt(np.sum(X_grid ** 2, -1))\n",
    "# # X_grid = (X_grid.T / normalization).T  # normalize each input\n",
    "\n",
    "# # features_grid = np.array(\n",
    "# #     [get_angles(x) for x in X_grid]\n",
    "# # )  # angles for state preparation are new features\n",
    "\n",
    "# X_grid = X_norm\n",
    "# features_grid = X_grid\n",
    "# predictions_grid = [variational_classifier(weights, bias, f) for f in features_grid]\n",
    "# # Z = np.reshape(predictions_grid, xx.shape)\n",
    "# Z = predictions_grid \n",
    "\n",
    "# # plot decision regions\n",
    "# cnt = plt.contourf(\n",
    "#     xx, yy, Z, levels=np.arange(-1, 1.1, 0.1), cmap=cm, alpha=0.8, extend=\"both\"\n",
    "# )\n",
    "# plt.contour(\n",
    "#     xx, yy, Z, levels=[0.0], colors=(\"black\",), linestyles=(\"--\",), linewidths=(0.8,)\n",
    "# )\n",
    "# plt.colorbar(cnt, ticks=[-1, 0, 1])\n",
    "\n",
    "# # plot data\n",
    "# plt.scatter(\n",
    "#     X_train[:, 0][Y_train == 1],\n",
    "#     X_train[:, 1][Y_train == 1],\n",
    "#     c=\"b\",\n",
    "#     marker=\"o\",\n",
    "#     edgecolors=\"k\",\n",
    "#     label=\"class 1 train\",\n",
    "# )\n",
    "# plt.scatter(\n",
    "#     X_val[:, 0][Y_val == 1],\n",
    "#     X_val[:, 1][Y_val == 1],\n",
    "#     c=\"b\",\n",
    "#     marker=\"^\",\n",
    "#     edgecolors=\"k\",\n",
    "#     label=\"class 1 validation\",\n",
    "# )\n",
    "# # plt.scatter(\n",
    "# #     X_train[:, 0][Y_train == -1],\n",
    "# #     X_train[:, 1][Y_train == -1],\n",
    "# #     c=\"r\",\n",
    "# #     marker=\"o\",\n",
    "# #     edgecolors=\"k\",\n",
    "# #     label=\"class -1 train\",\n",
    "# # )\n",
    "# # plt.scatter(\n",
    "# #     X_val[:, 0][Y_val == -1],\n",
    "# #     X_val[:, 1][Y_val == -1],\n",
    "# #     c=\"r\",\n",
    "# #     marker=\"^\",\n",
    "# #     edgecolors=\"k\",\n",
    "# #     label=\"class -1 validation\",\n",
    "# # )\n",
    "\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17a310c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
